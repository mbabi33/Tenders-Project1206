# parse_app_main.py & organize_files.sh - Справочное руководство по коду

## Обзор проекта и потока данных

В рамках нашего проекта по анализу тендерных данных, собранных с грузинского портала госзакупок, эти два скрипта являются следующим логическим шагом после сбора HTML-страниц с помощью `C17.py`. Поток данных выглядит так:

1.  **`C17.py`:** Собирает все HTML-вкладки для каждого тендера (5 страниц на тендер) в единую директорию `html_tabs` внутри `ML_DATA/T_CPV_CODE/`.
2.  **`organize_files.sh`:** Берет эти собранные HTML-файлы из `html_tabs` и распределяет их по специализированным поддиректориям (например, `app_main`, `app_bids`, `app_docs` и т.д.) для дальнейшей обработки.
3.  **`parse_app_main.py` (и аналогичные парсеры):** Обрабатывает HTML-файлы из своей специфической поддиректории (`app_main/` в данном случае), извлекая структурированные данные и сохраняя их в базу данных SQLite.

Эта модульная структура позволяет эффективно управлять большим объемом файлов и упрощает разработку специализированных парсеров.

## organize_files.sh

### Об этом скрипте

`organize_files.sh` – это простой, но очень эффективный bash-скрипт, чья основная задача – навести порядок в огромной куче HTML-файлов, собранных `C17.py`. Представьте, за год у нас могут быть десятки тысяч тендеров, и каждый тендер генерирует 5 HTML-страниц. Это сотни тысяч файлов в одной директории (`html_tabs`)! Навигация по такой директории, а главное – попытка последующих скриптов найти там нужные файлы, становится невыносимой и неэффективной.

Этот скрипт решает проблему, распределяя файлы по соответствующим поддиректориям на основе их названий, которые строго заданы `C17.py` (например, все `*_app_main.html` идут в `app_main/`).

### Аргументы командной строки

*   `$1` (обязательный): `<путь_к_рабочему_каталогу>` - Корневая директория проекта, обычно это `ML_DATA/T_CPV_CODE/`.
*   `$2` (опциональный): `--compress` - Флаг, который указывает скрипту, что перед организацией файлов нужно создать `tar.gz` архив исходной папки `html_tabs`. Полезно для резервного копирования или экономии места.

### Алгоритм работы

1.  **Валидация:** Проверяет, что `$1` (рабочий каталог) указан и что исходная директория `html_tabs` (`$1/html_tabs`) существует.
2.  **Архивирование (опционально):** Если передан флаг `--compress`:
    *   Создает архив `html_tabs_archive_YYYY-MM-DD.tar.gz` в `$1/`.
    *   Сжимает все содержимое `$1/html_tabs` в этот архив.
    *   Продолжает выполнение скрипта, даже если при сжатии возникли ошибки (логирует предупреждение).
3.  **Подготовка целевых директорий:** Создает (если еще нет) следующие поддиректории внутри `$1/`: `app_main`, `app_bids`, `app_docs`, `agency_docs`, `agr_docs`.
4.  **Групповое перемещение файлов:** Использует bash-функцию `shopt -s nullglob` (чтобы шаблоны, не нашедшие файлов, не приводили к ошибкам `mv`) и выполняет серию команд `mv`.
    *   Для каждого типа вкладки (например, `app_main`, `app_bids`) скрипт находит все файлы, соответствующие определенному шаблону (например, `*app_main*` для `app_main/`), и перемещает их в соответствующую целевую директорию.
    *   `echo` используется для логирования прогресса и количества перемещенных файлов.
5.  **Завершение:** Отключает `nullglob` и выводит сообщение о завершении организации.

### Обоснование принятых решений

*   **Необходимость скрипта `organize_files.sh`:** Этот скрипт критически важен для управления данными. Без него директория `html_tabs` быстро становится переполненной сотнями тысяч файлов, что делает ее неуправляемой и резко замедляет последующие операции файловой системы. Разделение файлов по их назначению:
    *   **Улучшает навигацию:** Человеку легко найти нужный тип файлов.
    *   **Оптимизирует парсеры:** Последующие скрипты (например, `parse_app_main.py`) могут работать со значительно меньшими, целевыми директориями, что упрощает их логику и повышает производительность.
    *   **Повышает надежность:** Снижает вероятность ошибок, связанных с некорректной обработкой файлов другого типа.
*   **Использование шаблонов `*app_main*`:** Было решено оставить текущие шаблоны, такие как `*app_main*`, вместо более строгих `*_app_main.html`. Это основывается на уверенности в точности именования файлов, генерируемых `C17.py`, и отсутствии проблем с перекрытием названий. Если бы именование было менее строгим, тогда потребовались бы более специфичные шаблоны.
*   **Флаг `--compress`:** Обеспечивает удобный механизм архивирования исходных HTML-файлов, что полезно для сохранения исходных данных и экономии дискового пространства после перемещения.

## parse_app_main.py

### Об этом скрипте

`parse_app_main.py` – это Python-скрипт, который специализируется на извлечении структурированной информации из HTML-файлов, содержащих **основные данные о тендерах** (файлы `*_app_main.html`). Эти файлы, предварительно организованные скриптом `organize_files.sh` в директорию `app_main/`, парсятся для получения 23+ полей данных о каждом тендере. Извлеченные данные затем сохраняются во временную базу данных SQLite (`tenders.db`), которая выступает в качестве промежуточного хранилища перед агрегацией в центральную базу.

### Ключевые технологии и зависимости

*   **Python 3:** Основа скрипта.
*   **`sqlite3`:** Встроенный модуль Python для работы с базой данных SQLite. Используется для создания таблицы, вставки и управления данными.
*   **`BeautifulSoup4`:** Мощная библиотека для парсинга HTML. Используется для навигации по DOM-структуре HTML-страниц и извлечения данных по текстовым меткам и структуре.
*   **`logging` модуль:** Для структурированного и гибкого вывода информации о ходе выполнения, предупреждений и ошибок. Обеспечивает единообразие с другими скриптами проекта (`C17.py`).
*   **`datetime` модуль:** Используется для корректного извлечения года из полей дат.
*   **`config.py`:** Внешний конфигурационный модуль, предоставляющий стандартизированные пути к рабочим директориям и файлам БД.

### Аргументы командной строки

*   `-c`, `--cpv` (обязательный): CPV-код, для которого осуществляется обработка файлов. Используется для определения корректных путей через `config.py`.
*   `-root`, `--root-dir` (опциональный): Корневая директория проекта, которая может переопределять значение по умолчанию из `config.py`.

### Алгоритм работы

1.  **Инициализация:**
    *   **Парсинг аргументов:** Обработка `cpv` и `root-dir`.
    *   **Настройка логирования:** Инициализация модуля `logging` для вывода сообщений в консоль (уровень INFO).
    *   **Получение путей:** Через `config.get_project_paths` определяются пути к базе данных (`DB_NAME`) и директории с HTML-файлами (`HTML_DIR`, которая в данном случае будет `$WORK_DIR/app_main`).
    *   **Валидация:** Проверка существования `HTML_DIR`.
    *   **Инициализация БД (`init_db`):** Подключается к `DB_NAME`. Важно: **удаляет существующую таблицу `tenders`** (`DROP TABLE IF EXISTS tenders`) и создает новую схему с 24 полями. Это сознательное решение для обеспечения чистого состояния временной БД при каждом запуске, так как данные затем переносятся в центральную базу.

2.  **Итерация и парсинг файлов:**
    *   Получает список всех HTML-файлов, заканчивающихся на `_app_main.html` из `HTML_DIR`.
    *   Итерирует по каждому файлу, вызывая `parse_tender_file`.

3.  **Парсинг одного файла (`parse_tender_file`):**
    *   **Чтение HTML:** Открывает HTML-файл и создает объект `BeautifulSoup`.
    *   **Извлечение из имени файла:** Извлекает `tenderCodePrefix` (например, `NAT`) и `tender_db_id` (уникальный числовой ID) из имени файла с помощью регулярных выражений.
    *   **Извлечение из HTML-контента:** Использует вспомогательные функции для извлечения различных полей:
        *   `get_field_text(label)`: Находит `<td>` с заданным текстом-меткой (например, "შესყიდვის ტიპი") и возвращает текст его соседнего `<td>`.
        *   `get_classifier_codes()`: Специально парсит список кодов классификатора.
        *   **Парсинг цен и валют:** Использует регулярные выражения для извлечения числовых значений (цен, бидов) и трехбуквенных кодов валют, обрабатывая грузинские разделители (`'` или `,`).
        *   **Парсинг `lotsDeliveryPlace`:** Пытается извлечь место доставки из поля `lotsName` с помощью регулярных выражений, ища грузинские маркеры (например, "სოფელ", "ქალაქ").
        *   **Извлечение `year`:** Год теперь динамически извлекается из поля `lotsDate` (даты объявления тендера), а не жестко закодирован. Используется `datetime.strptime`.
    *   **Сохранение в БД:** Подключается к SQLite и пытается вставить извлеченные данные.
        *   Обрабатывает `sqlite3.IntegrityError` для дубликатов `lotsNumber` (который определен как `UNIQUE`), логируя пропуск.
        *   Обрабатывает общие исключения, логируя ошибки.

4.  **Завершение:**
    *   Выводит сводку о количестве обработанных файлов.
    *   Закрывает все соединения с БД.

### Обоснование принятых решений

*   **`DROP TABLE IF EXISTS tenders` при каждом запуске:** Это сделано намеренно. Таблица `tenders` в данной базе данных SQLite является **временным буфером**. Данные из нее предполагается перемещать в центральную базу данных на последующих этапах. Таким образом, каждый запуск скрипта начинается с чистой таблицы, что упрощает отладку и гарантирует свежесть данных для текущей пакетной обработки.
*   **Отсутствие "умного" обновления для парсинга файлов:** В отличие от `C17.py`, здесь нет сложной логики сравнения с предыдущими записями для решения, парсить ли файл. Скрипт просто обрабатывает все файлы `*_app_main.html` в своей директории. Дубликаты на уровне БД предотвращаются благодаря ограничению `UNIQUE` на поле `lotsNumber`, которое вызывает `sqlite3.IntegrityError` при попытке вставки уже существующей записи. Этот подход считается приемлемым, так как данные все равно являются промежуточными.
*   **Извлечение `year` из `lotsDate`:** Вместо жесткого кодирования года (например, `2024`) скрипт теперь динамически парсит год из поля `lotsDate` (`შესყიდვის გამოცხადების თარიღი`). Это значительно повышает гибкость и точность скрипта, позволяя ему корректно работать с данными за любые периоды.
*   **Внедрение `logging`:** Переход от `print()` к стандартному модулю `logging` обеспечивает:
    *   **Единообразие:** Согласуется с практиками, принятыми в `C17.py` и по всему проекту.
    *   **Контроль:** Позволяет управлять уровнями детализации сообщений (INFO, WARNING, ERROR) и при необходимости перенаправлять их в файлы, что бесценно для отладки и мониторинга больших объемов данных.
    *   **Информативность:** Повышает читаемость и полезность вывода скрипта.
*   **Логика извлечения `lotsDeliveryPlace`:** Текущая реализация полагается на поиск специфических грузинских слов-маркеров. Хотя это решение может быть хрупким при изменении формата текста, оно признано достаточным для текущих данных. В будущем, при необходимости более высокой точности, этот модуль может быть расширен с использованием более продвинутых методов NLP или более гибких регулярных выражений.

## Инструкции по запуску

Эти скрипты выполняются последовательно.

1.  **Запустите `C17.py`:** Сначала необходимо запустить `C17.py` для сбора HTML-страниц в директорию `ML_DATA/T_CPV_CODE/html_tabs`.

    ```bash
    #!/bin/bash
    source ~/projects/venv/bin/activate
    python C17.py -root ML_DATA/ -c 45200000 -ds 01.01.2024 -de 10.01.2024 -ps 1 -pe 5
    deactivate
    ```

2.  **Запустите `organize_files.sh`:** После сбора HTML-файлов запустите `organize_files.sh` для их распределения по поддиректориям. Замените `<путь_к_рабочему_каталогу>` на соответствующий путь (например, `ML_DATA/T_45200000`).

    ```bash
    #!/bin/bash
    ./organize_files.sh ML_DATA/T_45200000
    # Или с опциональным сжатием:
    # ./organize_files.sh ML_DATA/T_45200000 --compress
    ```

3.  **Запустите `parse_app_main.py`:** Затем запустите `parse_app_main.py` для парсинга файлов из директории `app_main/` и сохранения данных в SQLite базу данных.

    ```bash
    #!/bin/bash
    source ~/projects/venv/bin/activate
    python parse_app_main.py -root ML_DATA/ -c 45200000
    deactivate
    ```

Убедитесь, что все Python-зависимости (pandas, selenium, beautifulsoup4, logging) установлены в вашем виртуальном окружении.